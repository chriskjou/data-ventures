{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ventures Trainee Workshop; Week 5: \n",
    "## Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another unsupervised learning model that is widely used in areas of temporal pattern recognition such as speech recognition, gesture recognition, and bioinformatics\n",
    "\n",
    "<img src = \"https://mioalter.files.wordpress.com/2015/12/thickerhmm4.png\"/ width=\"400\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps: Markov Chains ##\n",
    "- Hidden Markov Models are based on a concept called Markov Chains\n",
    "- If you've taken stat 110 or stat 171 or studied this subject before, feel free to skip this section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chains are an extremely useful concept in probability and statistics that model the idea of future outcomes being independent of the past once you know the present. For example, this is a highly unrealistic model, but suppose you live in an imaginary world where there are only two possibilities for weather on a given day: sunny and rainy, and you are trying to predict whether it will rain tomorrow. Suppose you also know the history of the weather up to today. So, the data you have are whether it was rainy or sunny today, whether it was rainy or sunny yesterday, etc. The **Markov property** would say that if you know the weather today, none of the past history besides today can be used predict the weather tomorrow. Stating this in terms of probability:\n",
    "\n",
    "$$P(X_{n+1} | X_1, X_2,X_3, \\dots, X_n) = P(X_{n+1} | X_n)$$\n",
    "\n",
    "If you haven't seen this notation before, don't worry. By $P(\\textbf{something})$, we mean the probability that \"something\" happens, and the stuff beyond the vertical line is the past information that we have that we are conditioning on. For example, if X is the outcome you get from rolling a standard die, $P(X = 3 | X< 4) = \\frac{1}{3}$, since the possibilities are $1,2,$ and $3$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, what are the problems with this as a model? For one thing, it's pretty unrealisic to have weather only depend on the most recent day. But, we can solve that by expanding the state space of our markov chain; for example, we could have our $X_i$'s represent the weather from the last three days. This also isn't entirely satisfying though, since a priori, we don't really know how far back in time we want our model to go. That's where **Hidden Markov Models** are useful: we assume that the variables we observe (in this case, the weather) are dependent on some *hidden* Markov chain that we don't get to observe (in this case, some weird process that goes on up in the sky that we can't see).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Models ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image included at the beginning of this preview sums up the process pretty well. The $H_i$s are the hidden Markov chain, and we don't get to observe these but we assume they exist for the purpose of our model.\n",
    "The $O_i$s are what we observe. These are called the **emissions** of the model. First, notice that without knowing the $H_i$s, we can't really draw any conclusions about the independence structure of the $O_i$s. That is, the $O_i$s don't have the Markov property that we talked about above even though the $H_i$s do. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about how this would apply to a speech recognition problem. In speech recognition, our observations are a sequence of frequencies, detected by a machine, and we are trying to deduce the sequence of phonemes that correspond to those frequencies. So, we can think of the hidden states as the true phonemes, the $H_i$s, and the frequency of sound that we observe as the $O_i$. In this particular problem, our question of interest is: How do we learn what the $H_i$s are? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Parameters of HMM\n",
    "\n",
    "The machine learning question we need to solve is estimating three types of parameters of the model: the transition probabilities of the Markov chain, the initial state distribution, and the emission probabilities. \n",
    "\n",
    "### The data that we have: \n",
    "- We have data of the form:\n",
    "$$\\{\\mathbf{x_i}\\}_{i=1}^N; x_i = (x_{i,1}, x_{i,2},\\dots,x_{i,n})  $$\n",
    "- There are $N$ observations, and each one is a sequence of $n$ outputs.\n",
    "\n",
    "### The Expectation Maximization Algorithm \n",
    "**Broad overview**: The question of interest is really, what are the parameters $T,\\pi, \\theta$ that maximize the likelihood of the data we observe (the $O_i$s in the diagram), where $T$ is the transition matrix of the Hidden Markov Chain, $\\pi$ contains the emission probabilities, and $\\theta$ is the initial distribution for the first hidden state.\n",
    "\n",
    "This is a very hard question to answer, since to obtain the likelihood of our data, we would have to sum out over all possibilities for $H$s, the hidden state sequence since we don't observe it directly. It actually makes the maximum likelihood estimation problem impossible to solve analytically, which you can see if you explore the more mathematically rigorous treatment of the topic provided in the link below. The general principle of the expectation maximization algorithm is that we move closer to the true maximum likelihood parameters in two steps:\n",
    "- **Expectation Step**: We assume we have $T$, the transition matrix of the Hidden States,$\\pi$,the emission probabilities of observed values, $\\theta$, the distribution over the first Hidden State. Then we estimate the probability distribution over the hidden states (conditioned on our observed data) and the probability distribution over each state transition (conditioned on our observed data). In practice, this process is done via the forward/backward algorithm. \n",
    "\n",
    "- **Maximization Step**: Now,we assume we don't have $T$, $\\theta$ and $\\pi$ and do maximum likelihood estimation on the *expected value* of the likelihood function (using our probability distribution over the hidden states and probability distribution over the transitions between hidden states) to compute new estimates for $T,\\pi, \\theta$, which are then used again in step 1.\n",
    "- **Repeat until convergence**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The mathematical details are out of scope for the Trainee program; but here's a link for those that are curious: https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/em-hmm.pdf \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward/Backward Algorithm ##\n",
    "\n",
    "- This will be covered by George during the workshop. This is how we do the E step in expectation maximization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Challenge Question:  \n",
    "### *Inference in HMM*\n",
    "\n",
    "We have a hidden Markov model with observations $X_1,X_2, \\dots$ and hidden states $S_1, S_2 \\dots $\n",
    "\n",
    "For a Markov chain with a finite number of states, we have the concept of a transition matrix, which might look something like this:\n",
    "\n",
    "<img src = \"http://academic.uprm.edu/wrolke/esma6789/graphs/mark164.png\"/ width=\"400\" height=\"400\"> \n",
    "\n",
    "\n",
    "The $i,j$th entry of the transition matrix is the probability of going from state $i$, to state $j$. \n",
    "\n",
    "\n",
    "In this problem you will perform **inference** on a Hidden Markov Model where the parameters (transition probabilities, initial state, and emission probabilities) are already known. In practice you would use expectation maximization to learn the parameters before doing inference.\n",
    "\n",
    "### A Dishonest Casino \n",
    "\n",
    "A casino sometimes uses a fair die and sometimes uses a loaded die, according to a Markov Chain. Our observations are the outcome of the die roll, but we don't know which die they are using, so it makes sense to model this as a Hidden Markov Model!\n",
    "\n",
    "Our Hidden Markov Model that has only two hidden states, State 1 (Fair Die) and State 2 (Loaded Die) . The probability of going from State 1 to State 2 is 0.2 and the probability of going from State 2 to State 1 is 0.4. We can represent the transition probabilities with a 2 x 2 matrix: \n",
    " \n",
    "\n",
    "$$\n",
    "   P =\n",
    "  \\left[ {\\begin{array}{cc}\n",
    "   0.8 & 0.2 \\\\\n",
    "   0.4 & 0.6 \\\\\n",
    "  \\end{array} } \\right]\n",
    " $$\n",
    " \n",
    "Also suppose that $S_1$ is drawn from the distribution $[2/3, 1/3]$. The emission probabilities are as follows:\n",
    "\n",
    "\n",
    "Given $S_i = 1$ (Fair Die) , $P(X_i = k | S_i = 1)$ is $\\frac{1}{6}$ for all six possible values of k. \n",
    "\n",
    "Given $S_i = 2$ (Loaded Die), $$P(X_i = 1 | S_i = 2) = 1/2$$ $$P(X_i = 2 | S_i = 2) = 1/4$$ $$P(X_i = 3 | S_i = 2) = 1/8$$ $$P(X_i = 4 | S_i = 2) = 1/16$$ $$P(X_i = 5 | S_i = 2) = 1/32$$ $$P(X_i = 6 | S_i = 2) = 1/32$$\n",
    " \n",
    " \n",
    "Complete the following code to write a forward/backward algorithm to compute the probability that \n",
    "you observe:\n",
    "$$ (X_1,X_2, \\dots X_{10}) = (1,2,3,4,3,2,1,2,3,4) $$\n",
    "\n",
    "For the purposes of this, don't worry about efficiency as long as it runs in a reasonable amount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "#The most efficient way to do this problem uses the Forward/Backward Algorithm, but\n",
    "#since we are dealing with small numbers here, anything will work\n",
    "\n",
    "#find probability of x of this form\n",
    "x = np.array([1,2,3,4,3,2,1,2,3,4])\n",
    "\n",
    "#Markov Chain S\n",
    "S = np.zeros((2,2))\n",
    "S[0,0] = 0.8\n",
    "S[0,1] = 0.2\n",
    "S[1,0] = 0.4\n",
    "S[1,1] = 0.6\n",
    "\n",
    "#Initial Distribution \n",
    "pi = np.array([2.0/3,1.0/3])\n",
    "\n",
    "def f(x,k,i,S,pi):\n",
    "    #write this function\n",
    "    pass \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
